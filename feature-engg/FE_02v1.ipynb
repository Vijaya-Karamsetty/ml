{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "TAKE THE IRIS DATA SET, OBTAINED FROM THE UNIVERSITY OF CALIFORNIA-IRVINE MACHINE LEARNING REPOSITORY (LINK PROVIDED IN THE REFERENCE SECTION), AS A DATA SET TO BE DISCRETIZED. PERFORM DATA DISCRETIZATION FOR EACH OF FOUR NUMERIC ATTRIBUTE USING CHIMERGE METHOD. (LET THE STOPPING CRITERIA BE: MAX-INTERVAL 6). YOU NEED TO WRITE A SMALL PYTHON PROGRAM RO DO THIS TO AVOID CLUMSY NUMERICAL COMPUTATIONS. SUBMIT YOUR SIMPLE ANALYSIS AND YOUR TEST RESULTS: SPLIT-POINTS, FINAL INTERVALS AND THE WELL DOCUMENTED SOURCE PROGRAM IN PYTHON JUPYTER NOTEBOOK. \n",
    "\n",
    "Objective :\n",
    "1. SPLIT POINTS\n",
    "2. FINAL INTERVALS\n",
    "3. CHI-MERGE SOURCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "### Read Iris Data from the web\n",
    "\n",
    "> IRIS Data set [http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data] can be read with the help of pandas read_csv into a dataframe\n",
    "\n",
    "> Set the Column/Header Names as\n",
    "    1. 'Sepal_Length' \n",
    "    2. 'Sepal_Width' \n",
    "    3. 'Petal_Length'\n",
    "    4. 'Petal_Width' \n",
    "    5. 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for the implementation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IRIS Data into the DataFrame\n",
    "iris_frame = pd.read_csv(\n",
    "    'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "    header=None)\n",
    "iris_frame.columns = [\n",
    "    'Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Class'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the Chi-Merge algorithm\n",
    "\n",
    "#### Algorithm Psuedo Code: \n",
    "1. Sort the Data set with the help of feature set\n",
    "\n",
    "2. Pick the unique values as intervals. Refer Pandas qcut[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html]\n",
    "\n",
    "3. Iterate till the intervals are greater than the input interval\n",
    "\n",
    "   + Iterate over the intervals and pick adjacent intervals\n",
    "   + Calculate the chi distance between the picked intervals   \n",
    "   + Identify the Minimum chi value from the calculations\n",
    "   + Perform the Merger of the adjacents\n",
    "\n",
    "\\begin{equation}\n",
    "\\chi^2=\\Sigma\\frac{(O-E)^2}{E} \\\\\n",
    "\\text{Where O is the actual value and E is the expected value.}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source - ChiMerge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChiMerge:\n",
    "\n",
    "    __author__ = 'Vijay Karamsetty'\n",
    "    '''\n",
    "        Takes the dataset and nominal col for the discretization and\n",
    "    '''\n",
    "    def __init__(self, data_set, nominal_col, verbose=False):\n",
    "        self.data = data_set\n",
    "        self.nominal_col = nominal_col\n",
    "        self.verbose = verbose\n",
    "        if nominal_col != None:\n",
    "            self.nominal_set = set(self.data[nominal_col])\n",
    "        print(self)\n",
    "\n",
    "    '''\n",
    "        Step 1 : Method will be used to sort the dataset with the help of given column/feature\n",
    "    '''\n",
    "    def get_sorted_data_set(self, data_set, feature):\n",
    "        if feature != None:\n",
    "            return data_set.sort_values(by=[feature])\n",
    "        #Return the Dataset as is\n",
    "        return data_set\n",
    "\n",
    "    '''\n",
    "        Step 2: Calculated chisquare for the observations of two intervals\n",
    "         a. Count the observations on the each data set into observation rows for the classes\n",
    "         b. Summarize the observations into row sums and column sums\n",
    "         c. Calculate the expected as row_sum(i)* column_sum(j) / total observations\n",
    "         d. Calculate the chi as sum of all (observed-expected)**2/expected\n",
    "    '''\n",
    "    def chi_square(self, observation_bin1, observation_bin2, nominal_col,\n",
    "                   feature, nominal_set):\n",
    "        expected_dictionary = {nominal: 0 for nominal in nominal_set}\n",
    "        observation_row1 = np.array([\n",
    "            cnt_observations for cls, cnt_observations in {\n",
    "                **expected_dictionary,\n",
    "                **Counter(observation_bin1[nominal_col])\n",
    "            }.items()\n",
    "        ])\n",
    "        observation_row2 = np.array([\n",
    "            cnt_observations for cls, cnt_observations in {\n",
    "                **expected_dictionary,\n",
    "                **Counter(observation_bin2[nominal_col])\n",
    "            }.items()\n",
    "        ])\n",
    "        all_observations = len(observation_row1) + len(observation_row2)\n",
    "        interval_observation_sum = observation_row1 + observation_row2\n",
    "        e_00 = interval_observation_sum * sum(\n",
    "            observation_row1) / all_observations\n",
    "        e_11 = interval_observation_sum * sum(\n",
    "            observation_row2) / all_observations\n",
    "\n",
    "        chi_2 = np.zeros(interval_observation_sum.shape)\n",
    "\n",
    "        if np.all(e_00):\n",
    "            chi_2 += (observation_row1 - e_00)**2 / e_00\n",
    "\n",
    "        if np.all(e_11):\n",
    "            chi_2 += (observation_row2 - e_11)**2 / e_11\n",
    "\n",
    "        return chi_2\n",
    "\n",
    "    '''\n",
    "        Implementing using group by of dataframes\n",
    "    '''\n",
    "    def chi_2(self, bin1, bin2, nominal_col, feature, nominal_set):\n",
    "        grouping_arr = []\n",
    "        expected_dictionary = {nominal: 0 for nominal in nominal_set}\n",
    "\n",
    "        observation_row1 = np.array([\n",
    "            (bin1[bin1[nominal_col] == i][feature].count())\n",
    "            for i in expected_dictionary\n",
    "        ])\n",
    "        observation_row2 = np.array([\n",
    "            (bin2[bin2[nominal_col] == i][feature].count())\n",
    "            for i in expected_dictionary\n",
    "        ])\n",
    "\n",
    "        all_observations = len(observation_row1) + len(observation_row2)\n",
    "        interval_observation_sum = observation_row1 + observation_row2\n",
    "        e_00 = interval_observation_sum * sum(\n",
    "            observation_row1) / all_observations\n",
    "        e_11 = interval_observation_sum * sum(\n",
    "            observation_row2) / all_observations\n",
    "\n",
    "        chi_2 = np.zeros(interval_observation_sum.shape)\n",
    "\n",
    "        if np.all(e_00):\n",
    "            chi_2 += (observation_row1 - e_00)**2 / e_00\n",
    "\n",
    "        if np.all(e_11):\n",
    "            chi_2 += (observation_row2 - e_11)**2 / e_11\n",
    "\n",
    "        return chi_2\n",
    "\n",
    "    '''\n",
    "        Performs the merge of i with adjacent i.e. i+1 interval and results into a new one with\n",
    "        Interval(i.left, i+1.right)\n",
    "    '''\n",
    "    def merge_indices(self, intervals, index):\n",
    "        # New Interval List\n",
    "        new_intervals = []\n",
    "        try:\n",
    "            skip_next = False\n",
    "            for i in range(len(intervals)):\n",
    "                #left of i, right of i+1 is the new interval\n",
    "                if (i == index) or (i - 1 == index):\n",
    "                    if not skip_next:\n",
    "                        new_intervals.append(\n",
    "                            pd.Interval(intervals[i].left,\n",
    "                                        intervals[i + 1].right))\n",
    "                        skip_next = True\n",
    "                else:\n",
    "                    new_intervals.append(intervals[i])\n",
    "        except ValueError:\n",
    "            print('Invalid index manipulation')\n",
    "        return new_intervals\n",
    "\n",
    "    def get_distinct_bins(self, data_set, feature):\n",
    "        #Identify the Unique data for the feature\n",
    "        unique_set_len = len(set(data_set[feature]))\n",
    "\n",
    "        # Split into bins with the help of unique set len that is provided\n",
    "        bins, init_split_points = pd.qcut(data_set[feature],\n",
    "                                          q=unique_set_len,\n",
    "                                          retbins=True,\n",
    "                                          duplicates='drop')\n",
    "        if self.verbose:\n",
    "            print(['Intervals'], bins)\n",
    "\n",
    "        return bins.cat.categories\n",
    "\n",
    "    '''\n",
    "        Step 3 : chi-merge for the feature\n",
    "    '''\n",
    "    def chi_merge(self, feature, max_intervals):\n",
    "        # Step 1 : Get the Sorted Dataset\n",
    "        data_set = self.get_sorted_data_set(self.data, feature)\n",
    "        #Get the intervals for the discretization\n",
    "        intervals = self.get_distinct_bins(data_set, feature)\n",
    "        #perfrom looping till the intervals are reducted to the max_intervals\n",
    "        while len(intervals) > max_intervals:\n",
    "            interim_chi_values = []\n",
    "            for i in range(len(intervals) - 1):\n",
    "                bin1 = data_set[data_set[feature].between(\n",
    "                    intervals[i].left, intervals[i].right)]\n",
    "                bin2 = data_set[data_set[feature].between(\n",
    "                    intervals[i + 1].left, intervals[i + 1].right)]\n",
    "                chi_2 = self.chi_2(bin1, bin2, self.nominal_col, feature,\n",
    "                                        self.nominal_set)\n",
    "                #chi_2 = self.chi_2(bin1, bin2, self.nominal_col, feature,\n",
    "                #                       self.nominal_set)\n",
    "                \n",
    "                interim_chi_values.append(sum(chi_2))\n",
    "            if len(interim_chi_values) > 0:\n",
    "                intervals = self.merge_indices(\n",
    "                    intervals,\n",
    "                    interim_chi_values.index(min(interim_chi_values)))\n",
    "\n",
    "        return intervals\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"ChiMerge v[{}]\".format(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChiMerge v[1.0]\n",
      "Discretization Intervals for Feature Sepal_Length\n",
      "+--------------------+-------+\n",
      "|       Lower        | Upper |\n",
      "+--------------------+-------+\n",
      "| 4.2989999999999995 |  4.8  |\n",
      "|        4.8         | 4.929 |\n",
      "|       4.929        |  5.5  |\n",
      "|        5.5         |  5.7  |\n",
      "|        5.7         |  5.9  |\n",
      "|        5.9         |  7.9  |\n",
      "+--------------------+-------+\n",
      "Discretization Intervals for Feature Sepal_Width\n",
      "+-------+-------+\n",
      "| Lower | Upper |\n",
      "+-------+-------+\n",
      "| 1.999 |  2.8  |\n",
      "|  2.8  |  3.0  |\n",
      "|  3.0  |  3.1  |\n",
      "|  3.1  |  3.2  |\n",
      "|  3.2  |  3.5  |\n",
      "|  3.5  |  4.4  |\n",
      "+-------+-------+\n",
      "Discretization Intervals for Feature Petal_Length\n",
      "+-------+-------+\n",
      "| Lower | Upper |\n",
      "+-------+-------+\n",
      "| 0.999 |  4.4  |\n",
      "|  4.4  |  5.8  |\n",
      "|  5.8  |  5.96 |\n",
      "|  5.96 |  6.1  |\n",
      "|  6.1  | 6.507 |\n",
      "| 6.507 |  6.9  |\n",
      "+-------+-------+\n",
      "Discretization Intervals for Feature Petal_Width\n",
      "+-------+-------+\n",
      "| Lower | Upper |\n",
      "+-------+-------+\n",
      "| 0.099 |  1.3  |\n",
      "|  1.3  |  2.0  |\n",
      "|  2.0  |  2.1  |\n",
      "|  2.1  | 2.245 |\n",
      "| 2.245 |  2.3  |\n",
      "|  2.3  |  2.5  |\n",
      "+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "# Nominal Column used\n",
    "nominal_col = 'Class'\n",
    "cobj = ChiMerge(data_set=iris_frame, nominal_col=nominal_col, verbose=False)\n",
    "\n",
    "for feature in ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width']:\n",
    "    split_points = cobj.chi_merge(feature, max_intervals=6)\n",
    "    print(\"Discretization Intervals for Feature {}\".format(feature))\n",
    "    x = PrettyTable()\n",
    "    x.field_names = ['Lower', 'Upper']\n",
    "    for each in split_points:\n",
    "        x.add_row([each.left, each.right])\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
