{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installables\n",
    "> pip install webdriver-manager [https://pypi.org/project/webdriver-manager/]\n",
    "[https://www.kenst.com/2016/12/installing-marionette-firefoxdriver-on-mac-osx/]\n",
    "> pip install selenium\n",
    "\n",
    "> pip install bs4\n",
    "\n",
    "> pip install urllib3\n",
    "\n",
    "> Installing the Chrome Driver for Windows, Mac, and Linux [https://sites.google.com/a/chromium.org/chromedriver/]\n",
    "\n",
    "**Please note**: Try adding the chormedriver.exe to a path and carry the path, else webdriver will search in the system path for the binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prettytable\n",
      "  Downloading prettytable-0.7.2.tar.bz2 (21 kB)\n",
      "Building wheels for collected packages: prettytable\n",
      "  Building wheel for prettytable (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13698 sha256=0e1e2060425ae23339f869f753728c448a4e69fde4e0e9fac962389361f08303\n",
      "  Stored in directory: /Users/shraddha/Library/Caches/pip/wheels/8c/76/0b/eb9eb3da7e2335e3577e3f96a0ae9f74f206e26457bd1a2bc8\n",
      "Successfully built prettytable\n",
      "Installing collected packages: prettytable\n",
      "Successfully installed prettytable-0.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import concurrent.futures\n",
    "import urllib.request\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as cond\n",
    "from selenium.common.exceptions import NoAlertPresentException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from collections import deque\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "\n",
    "# for the webdriver help\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Uncomment the below for the windows setup\n",
    "#driver = webdriver.Chrome(\"C:\\\\aiml\\\\chromedriver\", options=chrome_options)\n",
    "\n",
    "# Product Retrieval Dictionary\n",
    "# root{ elementkey : [selector, attribute]}\n",
    "\n",
    "grofers_meta_data_dict = {\n",
    "    'a.product__wrapper': {\n",
    "        '1. Name': {\n",
    "            'selector': 'div.plp-product__name',\n",
    "            'text': False,\n",
    "            'attrib': 'title'\n",
    "        },\n",
    "        '2. Quantity': {\n",
    "            'selector': 'div.plp-product__quantity',\n",
    "            'text': False,\n",
    "            'attrib': 'title'\n",
    "        },\n",
    "        '3. Price': {\n",
    "            'selector': 'span.plp-product__price--new', \n",
    "            'text': False,\n",
    "            'attrib': 'innerText'\n",
    "        },\n",
    "        '4. Discount': {\n",
    "            'selector': 'div.plp-product__offer',\n",
    "            'text': False,\n",
    "            'attrib': 'innerText'\n",
    "        },\n",
    "        '5. Membership-price': {\n",
    "            'selector': 'div.plp-product__non-member-price',\n",
    "            'text': False,\n",
    "            'attrib': 'innerText'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "# Targetted Enumeration for the Project\n",
    "\n",
    "class FMCG_Category(enum.Enum):\n",
    "    VEGETABLES = 1\n",
    "    BEVERAGES = 2\n",
    "    STAPLES = 3\n",
    "    SNACKS = 4\n",
    "    DAIRY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Groffer Scrappable URLS for the FMCG\n",
    "'''\n",
    "\n",
    "URLS = {\n",
    "    FMCG_Category.VEGETABLES:\n",
    "    'https://grofers.com/cn/vegetables-fruits/cid/1487',\n",
    "    FMCG_Category.BEVERAGES: 'https://grofers.com/cn/beverages/cid/12',\n",
    "    FMCG_Category.STAPLES: 'https://grofers.com/cn/grocery-staples/cid/16',\n",
    "    FMCG_Category.SNACKS:\n",
    "    'https://grofers.com/cn/biscuits-snacks-chocolates/cid/13',\n",
    "    FMCG_Category.DAIRY: 'https://grofers.com/cn/breakfast-dairy/cid/14'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Method to read the selector from the root element.\n",
    "'''\n",
    "\n",
    "\n",
    "def get_value(field_element, selector, is_text, attrib):\n",
    "    ret_val = ''\n",
    "    try:\n",
    "        # If the element is having value in the as text then is_text is required to be True\n",
    "        # else this function will try target the attribute value\n",
    "        if isinstance(field_element, WebElement):\n",
    "            selection = field_element.find_element_by_css_selector(selector)\n",
    "            ret_val = selection.text if is_text else selection.get_attribute(\n",
    "                attrib)\n",
    "    except NoSuchElementException:\n",
    "        return None\n",
    "    return ret_val\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Helps in scraping individual root element with the help of meta_data provided\n",
    "\n",
    "'''\n",
    "\n",
    "def scrape_individual_root(each_root_element, root_element_metadata):\n",
    "    product_rel_dict = {}\n",
    "    try:\n",
    "        #Each field is designed to have a selector from the root xpath\n",
    "        # and an attribute to capture or text if no attribute provided\n",
    "        for field in root_element_metadata:\n",
    "            field_meta_data = root_element_metadata[field]\n",
    "            product_rel_dict[field] = get_value(each_root_element,\n",
    "                                                field_meta_data['selector'],\n",
    "                                                field_meta_data['text'],\n",
    "                                                field_meta_data['attrib'])\n",
    "    except NoSuchElementException:\n",
    "        return None\n",
    "    return product_rel_dict\n",
    "\n",
    "\n",
    "def scrape_and_get_content(driver, url, meta_data_dict):\n",
    "    bag = pd.DataFrame()\n",
    "    # it is okay to return empty dataframe rather than just dying.\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        for meta_data_element in meta_data_dict:\n",
    "            # identifies each product root element with the metadata provided\n",
    "            # Need to implement the WebDriverWait(driver, 10)\n",
    "            #.until(EC.presence_of_element_located((By.ID, \"myDynamicElement\")))\n",
    "            meta_elements = driver.find_elements_by_css_selector(\n",
    "                meta_data_element)\n",
    "            # for each meta element get dictionary\n",
    "            for each_root_element in meta_elements:\n",
    "                product_rel_dict = scrape_individual_root(\n",
    "                    each_root_element, meta_data_dict[meta_data_element])\n",
    "                if product_rel_dict != None:\n",
    "                    bag = bag.append(pd.Series(data=product_rel_dict),\n",
    "                                     ignore_index=True)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    # Return the Collected Bag of Vegetables/Snacks/Beverages and etc.\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. Name</th>\n",
       "      <th>2. Quantity</th>\n",
       "      <th>3. Price</th>\n",
       "      <th>4. Discount</th>\n",
       "      <th>5. Membership-price</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>184</td>\n",
       "      <td>208</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>236</td>\n",
       "      <td>95</td>\n",
       "      <td>153</td>\n",
       "      <td>43</td>\n",
       "      <td>138</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Nestle Everyday Dairy Whitener</td>\n",
       "      <td>500 g</td>\n",
       "      <td>₹44</td>\n",
       "      <td>23% OFF</td>\n",
       "      <td>Club Price: ₹42</td>\n",
       "      <td>FMCG_Category.STAPLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               1. Name 2. Quantity 3. Price 4. Discount  \\\n",
       "count                              240         240      240         184   \n",
       "unique                             236          95      153          43   \n",
       "top     Nestle Everyday Dairy Whitener       500 g      ₹44     23% OFF   \n",
       "freq                                 2          30        7          36   \n",
       "\n",
       "       5. Membership-price               Category  \n",
       "count                  208                    240  \n",
       "unique                 138                      5  \n",
       "top        Club Price: ₹42  FMCG_Category.STAPLES  \n",
       "freq                     7                     48  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groffers_frame = pd.DataFrame()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    #Source https://docs.python.org/3/library/concurrent.futures.html\n",
    "    future_of_target = {\n",
    "        executor.submit(\n",
    "            scrape_and_get_content,\n",
    "            webdriver.Chrome(\"/users/shraddha/chromed/chromedriver\",\n",
    "                             options=chrome_options), URLS[url],\n",
    "            grofers_meta_data_dict): url\n",
    "        for url in URLS\n",
    "    }\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(future_of_target):\n",
    "        category = future_of_target[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "            if len(data) > 0:\n",
    "                data['Category'] = category\n",
    "                #Contact both the frames\n",
    "                groffers_frame = pd.concat([groffers_frame, data])\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (category, exc))\n",
    "            \n",
    "groffers_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#json Reader\n",
    "\n",
    "> PayTM uses json from the middleware services to load the Entire Page, so scraping the webelements is not necessay if we get hold of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mangoes\n",
      "298.00\n",
      "372.50\n",
      "veg\n",
      "Cabbage & Cauliflower\n",
      "19.00\n",
      "23.75\n",
      "veg\n",
      "Gourd, Pumpkin, Drumstick\n",
      "59.00\n",
      "73.75\n",
      "veg\n",
      "Indian & Exotic Herbs\n",
      "299.00\n",
      "373.75\n",
      "veg\n",
      "Kiwi, Melon, Citrus Fruit\n",
      "99.00\n",
      "123.75\n",
      "veg\n",
      "Kiwi, Melon, Citrus Fruit\n",
      "43.00\n",
      "53.75\n",
      "veg\n",
      "Apples & Pomegranate\n",
      "159.00\n",
      "198.75\n",
      "veg\n",
      "Root Vegetables\n",
      "11.00\n",
      "13.75\n",
      "veg\n",
      "Cucumber & Capsicum\n",
      "26.00\n",
      "32.50\n",
      "veg\n",
      "Kiwi, Melon, Citrus Fruit\n",
      "79.00\n",
      "98.75\n",
      "veg\n",
      "Leafy Vegetables\n",
      "179.00\n",
      "223.75\n",
      "veg\n",
      "Banana, Sapota & Papaya\n",
      "39.00\n",
      "48.75\n",
      "veg\n",
      "Apples & Pomegranate\n",
      "159.00\n",
      "198.75\n",
      "veg\n",
      "Exotic Fruits\n",
      "28.00\n",
      "35.00\n",
      "veg\n",
      "Cucumber & Capsicum\n",
      "8.00\n",
      "10.00\n",
      "veg\n",
      "Beans, Brinjals & Okra\n",
      "35.00\n",
      "43.75\n",
      "veg\n",
      "Seasonal Fruits\n",
      "52.00\n",
      "65.00\n",
      "veg\n",
      "Leafy Vegetables\n",
      "91.90\n",
      "110.15\n",
      "veg\n",
      "Leafy Vegetables\n",
      "109.90\n",
      "132.65\n",
      "veg\n",
      "Potato, Onion & Tomato\n",
      "14.00\n",
      "17.50\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def item_generator(json_input, lookup_key):\n",
    "    if isinstance(json_input, dict):\n",
    "        for k, v in json_input.items():\n",
    "            if k == lookup_key:\n",
    "                yield v\n",
    "            else:\n",
    "                yield from item_generator(v, lookup_key)\n",
    "    elif isinstance(json_input, list):\n",
    "        for item in json_input:\n",
    "            yield from item_generator(item, lookup_key)\n",
    "\n",
    "# download raw json object\n",
    "url = \"https://www.bigbasket.com/product/get-products/?slug=fruits-vegetables&page=2&tab_type=[%22all%22]&sorted_on=popularity&listtype=pc\"\n",
    "#https://www.bigbasket.com/product/get-products/?slug=fruits-vegetables&page=2&tab_type=[]&sorted_on=popularity&listtype=pc\"\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(\"/users/shraddha/chromed/chromedriver\",\n",
    "                          options=chrome_options)\n",
    "driver.get(url)\n",
    "try:\n",
    "    elem=driver.find_element_by_tag_name(\"pre\")\n",
    "    content=elem.text\n",
    "    j=json.loads(content)\n",
    "    #print(json.dumps(j, indent=4))\n",
    "    for y_item in item_generator(j, 'prods'):\n",
    "        if isinstance(y_item, list):\n",
    "            for each_product in y_item:\n",
    "                if isinstance(each_product, dict):\n",
    "                    #print(each_product)\n",
    "                    print(each_product['p_type'])\n",
    "                    print(each_product['llc_n'])\n",
    "                    print(each_product['sp'])\n",
    "                    print(each_product['mrp'])\n",
    "                   \n",
    "        \n",
    "except Exception as ex:\n",
    "    print(\"Encountered issue while parsing..\", ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[https://data-lessons.github.io/library-webscraping-DEPRECATED/]\n",
    "\n",
    "[https://www.techbeamers.com/locate-elements-selenium-python/]\n",
    "\n",
    "[https://pythonexamples.org/pandas-dataframe-add-append-row/]\n",
    "\n",
    "##### What is robots.txt?\n",
    "\n",
    "1. Flipkart[https://www.flipkart.com/robots.txt]\n",
    "2. https://www.digitalocean.com/community/tutorials/how-to-crawl-a-web-page-with-scrapy-and-python-3\n",
    "\n",
    "\n",
    "[https://selenium-python.readthedocs.io/locating-elements.html]\n",
    "Must Read on the 'selenium.webdriver.remote.webelement.WebElement'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
